[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT212 Portfolio",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "src/pv/pv-01.html",
    "href": "src/pv/pv-01.html",
    "title": "Professional Viz Sample",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Prof Viz",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Professional Viz Sample</span>"
    ]
  },
  {
    "objectID": "src/tt/2025-07-08.html",
    "href": "src/tt/2025-07-08.html",
    "title": "TidyTuesday Sample 1",
    "section": "",
    "text": "Global dataset for seized and non-intercepted illegal cheetah trade (Acinonyx jubatus) 2010–2019",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TidyTuesday Sample 1</span>"
    ]
  },
  {
    "objectID": "src/tt/2025-07-08.html#global-dataset-for-seized-and-non-intercepted-illegal-cheetah-trade-acinonyx-jubatus-20102019",
    "href": "src/tt/2025-07-08.html#global-dataset-for-seized-and-non-intercepted-illegal-cheetah-trade-acinonyx-jubatus-20102019",
    "title": "TidyTuesday Sample 1",
    "section": "",
    "text": "Variables\nThe variables within this dataset include: - Incident No.; Assigned by researcher\n- Incident Type; Animal Injury / Mortality / Welfare Possession/trade Seizure\n- Incident Date; DD-MMM-YY, TOTALS\n- Discovery Date; DD-MMM-YY (date when incident was discovered by researcher)\n- Country Role; O = Origin T = Transit D = Destination\n- Region\n- Country\n- City/Region\n- Location Type; Unknown, Rural area, Border Crossing, Private Home, Airport, Farm, etc.\n- Origin if known\n- Transit if known\n- Destination if known\n- Report grading;\n- Verif means; Photo and/or video, official records, source reliability, known sellers, image search.\n- Ultimate Source Type; A = Official, B = Database, C = Primary, D = Secondary, E = Seller\n- Ult.Verif.Source; E.g., photo, video, official records, site visit\n- Ult.Source Reliability; A = always B = mostly C = fairly D = sometimes E = unreliable F = unknown\n- Orig.Source Type; A = Original research B = Official C = Open source D = Direct Report\n- Medium; e.g. Email, phone, report, database\n- Original Source; Name or identifier\n- Day\n- Month\n- Year\n- Number of Cheetahs; If known and in full cheetah units.\n- Units; Bushmeat, Claws, Head, Live, Other, Skin, Skin pieces, Skull, Stuffed, Teeth, Trophy\n- Incident Description\n- Confiscated; number of units\n- Surrendered\n- Alive; number of live units at or post confiscation\n- Died; number of death units at or following confiscation if known\n- LTF / UNK Fate; number of units lost to follow up or unknown fate\n- Action Taken\n- Outcome\n- Detecting Agency\n- POI Assigned ID\n- Other info / URL\n\nCodestr(data)\n\ntibble [1,886 × 38] (S3: tbl_df/tbl/data.frame)\n $ Incident No.           : chr [1:1886] NA NA \"PT-2010-001\" \"PT-2010-002\" ...\n $ Incident Type          : chr [1:1886] \"Animal Injury / Mortality / Welfare\\r\\nPossession/trade\\r\\nSeizure\" NA \"Seizure\" \"Seizure\" ...\n $ Incident Date          : chr [1:1886] NA \"TOTALS\" \"40191\" \"40192\" ...\n $ Discovery Date         : num [1:1886] NA NA 44070 42300 41149 ...\n $ Country Role           : chr [1:1886] \"O = Origin\\r\\nT = Transit\\r\\nD = Destination\" NA \"D\" \"O\" ...\n $ Region                 : chr [1:1886] NA NA \"Europe\" \"East Africa\" ...\n $ Country                : chr [1:1886] NA NA \"Spain\" \"Kenya\" ...\n $ City/Region            : chr [1:1886] NA NA NA \"Mombasa\" ...\n $ Location Type          : chr [1:1886] NA NA \"Unknown\" \"Rural area\" ...\n $ Origin if known        : chr [1:1886] NA NA NA NA ...\n $ Transit if known       : chr [1:1886] NA NA \"E Europe\" NA ...\n $ Destination if known   : chr [1:1886] NA NA NA NA ...\n $ Report grading         : chr [1:1886] \"A = True\\r\\nB = Second hand but source known\\r\\nC = Unknown but corroborated\\r\\nD = Unable to Judge\\r\\nE = Suspected false\" NA \"D\" \"A\" ...\n $ Verif means            : chr [1:1886] NA NA \"Invest. report\" \"Seizure\" ...\n $ Ultimate source type   : chr [1:1886] \"A = Primary\\r\\nB = Secondary\" NA \"C\" \"A\" ...\n $ Ult. Verif. Source     : chr [1:1886] \"Description\" NA \"El Mundo (ES)\" \"Original source\" ...\n $ Ult. Source Reliability: chr [1:1886] \"A = always\\r\\nB = mostly\\r\\nC = fairly\\r\\nD = sometimes\\r\\nE = unreliable\\r\\nF = unknown\" NA \"C\" \"A\" ...\n $ Orig. Source Type      : chr [1:1886] \"A = Original research\\r\\nB = Official\\r\\nC = Open source\\r\\nD = Direct Report\" NA \"C\" \"B\" ...\n $ Medium                 : chr [1:1886] NA NA \"Media\" \"Web site/Direct\" ...\n $ Original Source        : chr [1:1886] NA NA \"24minutes.es\" \"CITES MA\" ...\n $ Day                    : chr [1:1886] NA NA \"13\" \"14\" ...\n $ Month                  : chr [1:1886] NA NA \"1\" \"1\" ...\n $ Year                   : chr [1:1886] NA NA \"2010\" \"2010\" ...\n $ Day (+/-)              : chr [1:1886] \"When exact date not known\" NA NA NA ...\n $ Month (+/-)            : chr [1:1886] \"When exact date not known\" NA \"-1\" NA ...\n $ # Cheetahs             : chr [1:1886] NA \"4184\" \"1\" \"1\" ...\n $ Units                  : chr [1:1886] \"Bushmeat\\r\\nClaws\\r\\nHead\\r\\nLive\\r\\nOther\\r\\nSkin\\r\\nSkin pieces\\r\\nSkull\\r\\nStuffed\\r\\nTeeth\\r\\nTrophy\" NA \"Live\" \"Skin\" ...\n $ Incident Description   : chr [1:1886] NA NA \"cheetah, lions,  tiger, Iberian wolf, European Lynx, 3 pumas, eagle and falcons seized. Animals were transporte\"| __truncated__ \"Transported on land as luggage, confiscated by KWS\" ...\n $ Confiscated            : chr [1:1886] \"# of units if known\" \"736\" \"1\" \"1\" ...\n $ Surrendered            : num [1:1886] NA 20 0 0 0 0 0 0 0 0 ...\n $ Alive                  : chr [1:1886] \"# live units at or post confiscation\" \"342\" \"1\" \"0\" ...\n $ Died                   : chr [1:1886] \"# death units at or post confiscation\" \"759\" \"0\" \"1\" ...\n $ LTF/ UNK Fate          : chr [1:1886] \"# units lost to follow up\" \"3083\" \"0\" \"0\" ...\n $ Action Taken           : chr [1:1886] NA NA \"Confiscated by SEPRONA as part of Operation \\\"Lobezno\\\"\" NA ...\n $ Outcome                : chr [1:1886] NA NA \"Eight people who sold wildlife products on the internet were arrested. Article provides data on detainees.\" \"1 arrested, 1  prosecuted for Illegal  possession and dealing.  1 given 18 months imprisonment or Kshs 63,000 in default\" ...\n $ Detecting agency       : chr [1:1886] NA NA \"SEPRONA (Nature Protection Service)\" \"Kenya Wildlife Service (KWS)\" ...\n $ POI Assigned ID        : chr [1:1886] \"Suspects, person of interest\" NA \"Unknown x 8\" \"Unknown\" ...\n $ Other info / URL       : chr [1:1886] \"URLs\" NA \"https://www.laregion.es/articulo/galicia/desarticulada-red-traficaba-especies-protegidas-comunidades-ellas-gali\"| __truncated__ \"https://cites.org/sites/default/files/eng/com/sc/66/E-SC66-32-05_Annex.pdf\" ...\n\n\nResearch Questions Development\nWhere were all live cheetahs found?\n\n\n\n\n\n\n\nI would like to use location to better understand how and what happened in these recorded illegal cheetah trade incidents. For example, I could bind this location data to different variables in the dataset to show spatially how many cheetahs were found in these countries.\nHow many cheetahs were found throughout the years?\n\n\n\n\n\n\n\n\n\nThis plot helped me see how many cheetahs were counted in all of the incidents recorded. I believe this can help me delve into questions such as:\n \n\nHow are illegal cheetah trade incidents changing in their locations, units, and incident types throughout the years?\nWhat are the most common incidents seen in the illegal cheetah trade?",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TidyTuesday Sample 1</span>"
    ]
  },
  {
    "objectID": "src/tt/2025-07-15.html",
    "href": "src/tt/2025-07-15.html",
    "title": "TidyTuesday Sample 2",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>TidyTuesday Sample 2</span>"
    ]
  },
  {
    "objectID": "src/ica/ica-sample1.html",
    "href": "src/ica/ica-sample1.html",
    "title": "ICA Sample 1",
    "section": "",
    "text": "Codelibrary(tidyverse)\nweather &lt;- read_csv(\"https://mac-stat.github.io/data/sfo_weather.csv\")\n\n\n\nCodelibrary(dplyr)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(readr)\n\nweather &lt;- read_csv(\"../../../portfolio-cluno113/data/raw/weather.csv\")\n\nweather &lt;- weather %&gt;% \n  mutate(PrecipYr = na_if(PrecipYr, 99999)) \n  \nweather &lt;- weather %&gt;% \n  mutate(date = as.Date(date, format = \"%m/%d/%y\")) %&gt;% \n  mutate(day_of_year = yday(date))\n\nweather_clean &lt;- weather %&gt;% \n  mutate(month_name = format(date, \"%b\"))\n\nwrite_csv(weather_clean, \"../../../portfolio-cluno113/data/raw/weather_clean.csv\")\n\nweather_clean &lt;- weather_clean |&gt; \n  janitor::clean_names()\n\nweather_clean$date &lt;- as.Date(weather_clean$date - 1, origin = \"2021-01-01\")\n\ntemp &lt;- ggplot(weather_clean, aes(x = date)) +\n  geom_linerange(aes(\n    ymin = record_low,\n    ymax = record_high),\n    color = \"#ECEBE3\") +\n  geom_linerange(aes(\n    ymin = normal_low,\n    ymax = normal_high),\n    color = \"#C8B8BA\") +\n  geom_linerange(aes(\n    ymin = low,\n    ymax = high),\n    color = \"#A90248\") +\n  scale_x_date(\n    date_labels = \"%b\",        # Short month names (Jan, Feb, ...)\n    date_breaks = \"1 month\"    # Tick every month\n  ) +\n  theme_classic() +\n  theme(axis.title = element_blank(),\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 9),\n    panel.grid = element_blank())\n\n\n\nCodeprec &lt;- ggplot(weather_clean) +\n  geom_area(aes(x = date, y = culm_prec), fill = \"#ebeae2\", color = \"#32a3d8\") +\n  geom_point(\n    data = subset(weather_clean, record_precip == TRUE),\n    aes(y = culm_prec),\n    shape = 17,\n    size = 2,\n    color = \"#32a3d8\"\n  ) +\n  scale_x_date(date_labels = \"%b\", date_breaks = \"1 month\") +\n  theme_classic()\n\n\n\nCodelibrary(patchwork)\ntemp / prec + plot_layout(widths = c(2, 1), heights = c(3, 1))",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ICA Sample 1</span>"
    ]
  },
  {
    "objectID": "src/ica/ica-sample2.html",
    "href": "src/ica/ica-sample2.html",
    "title": "ICA Sample 2",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ICA Sample 2</span>"
    ]
  },
  {
    "objectID": "src/exam/exam1.html",
    "href": "src/exam/exam1.html",
    "title": "exam1",
    "section": "",
    "text": "1 Introduction\n2 Review\nAdv Data Viz\n\nCodelibrary(dplyr)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(readr)\n\nweather_clean &lt;- weather_clean |&gt; \n  janitor::clean_names()\n\nweather_clean$date_in_year &lt;- as.Date(weather_clean$date_in_year - 1, origin = \"2021-01-01\")\n\ntemp &lt;- ggplot(weather_clean, aes(x = date_in_year)) +\n  geom_linerange(aes(\n    ymin = record_low,\n    ymax = record_high),\n    color = \"#ECEBE3\") +\n  geom_linerange(aes(\n    ymin = normal_low,\n    ymax = normal_high),\n    color = \"#C8B8BA\") +\n  geom_linerange(aes(\n    ymin = low,\n    ymax = high),\n    color = \"#A90248\") +\n  scale_x_date(\n    date_labels = \"%b\",        # Short month names (Jan, Feb, ...)\n    date_breaks = \"1 month\"    # Tick every month\n  ) +\n  theme_classic() +\n  theme(axis.title = element_blank(),\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 9),\n    panel.grid = element_blank())\n\nprec &lt;- ggplot(weather_clean) +\n  geom_area(aes(x = date_in_year, y = culm_prec), fill = \"#ebeae2\", color = \"#32a3d8\") +\n  geom_point(\n    data = subset(weather_clean, record_precip == TRUE),\n    aes(y = culm_prec),\n    shape = 17,\n    size = 2,\n    color = \"#32a3d8\"\n  ) +\n  scale_x_date(date_labels = \"%b\", date_breaks = \"1 month\") +\n  theme_classic()\n\n\n\nCodelibrary(patchwork)\ntemp / prec + plot_layout(widths = c(2, 1), heights = c(3, 1))\n\n\n\n\n\n\n\n6 Adv Data Wrangling P1\nLogicals\n\nCodex &lt;- c(TRUE, FALSE, NA)\nx\n\n[1]  TRUE FALSE    NA\n\nCodeclass(x)\n\n[1] \"logical\"\n\n\nYou will often create logical vectors with comparison operators: &gt;, &lt;, &lt;=, &gt;=, ==, !=.\n\nCodex &lt;- c(1, 2, 9, 12)\nx &lt; 2\n\n[1]  TRUE FALSE FALSE FALSE\n\nCodex &lt;= 2\n\n[1]  TRUE  TRUE FALSE FALSE\n\nCodex &gt; 9\n\n[1] FALSE FALSE FALSE  TRUE\n\nCodex &gt;= 9\n\n[1] FALSE FALSE  TRUE  TRUE\n\nCodex == 12\n\n[1] FALSE FALSE FALSE  TRUE\n\nCodex != 12\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n\nWhen you want to check for set containment, the %in% operator is the correct way to do this (as opposed to ==).\n\nCodex &lt;- c(1, 2, 9, 4)\nx == c(1, 2, 4)\n\n[1]  TRUE  TRUE FALSE FALSE\n\nCodex %in% c(1, 2, 4)\n\n[1]  TRUE  TRUE FALSE  TRUE\n\n\nThe Warning: longer object length is not a multiple of shorter object length is a manifestation of vector recycling.\nIn R, if two vectors are being combined or compared, the shorter one will be repeated to match the length of the longer one–even if longer object length isn’t a multiple of the shorter object length. We can see the exact recycling that happens below:\n\nCodex &lt;- c(1, 2, 9, 4)\nx == c(1, 2, 4)\n\n[1]  TRUE  TRUE FALSE FALSE\n\nCodex == c(1, 2, 4, 1) # This line demonstrates the recycling that happens on the previous line\n\n[1]  TRUE  TRUE FALSE FALSE\n\n\nLogical vectors can also be created with functions. is.na() is one useful example:\n\nCodex &lt;- c(1, 4, 9, NA)\nx == NA\n\n[1] NA NA NA NA\n\nCodeis.na(x)\n\n[1] FALSE FALSE FALSE  TRUE\n\n\nWe can negate a logical object with !. We can combine logical objects with & (and) and | (or).\n\nCodex &lt;- c(1, 2, 4, 9)\nx &gt; 1 & x &lt; 5\n\n[1] FALSE  TRUE  TRUE FALSE\n\nCode!(x &gt; 1 & x &lt; 5)\n\n[1]  TRUE FALSE FALSE  TRUE\n\nCodex &lt; 2 | x &gt; 8\n\n[1]  TRUE FALSE FALSE  TRUE\n\n\nWe can summarize logical vectors with:\nany(): Are ANY of the values TRUE? all(): Are ALL of the values TRUE? sum(): How many of the values are TRUE? mean(): What fraction of the values are TRUE?\n\nCodex &lt;- c(1, 2, 4, 9)\nany(x == 1)\n\n[1] TRUE\n\nCodeall(x &lt; 10)\n\n[1] TRUE\n\nCodesum(x == 1)\n\n[1] 1\n\nCodemean(x == 1)\n\n[1] 0.25\n\n\nif_else() and case_when() are functions that allow you to return values depending on the value of a logical vector. You’ll explore the documentation for these in the following exercises.\nNote: ifelse() (from base R) and if_else() (from tidyverse) are different functions. We prefer if_else() for many reasons (examples below).\nNoisy to make sure you catch issues/bugs Can explicitly handle missing values Keeps dates as dates\n\nCodex &lt;- c(-1, -2, 4, 9, NA)\n\nifelse(x &gt; 0, 'positive', 'negative')\n\n[1] \"negative\" \"negative\" \"positive\" \"positive\" NA        \n\nCodeif_else(x &gt; 0, 'positive', 'negative')\n\n[1] \"negative\" \"negative\" \"positive\" \"positive\" NA        \n\nCodeifelse(x &gt; 0, 1, 'negative') # Bad: doesn't complain with combo of data types\n\n[1] \"negative\" \"negative\" \"1\"        \"1\"        NA        \n\nCode# if_else(x &gt; 0, 1, 'negative') # Good:noisy to make sure you catch issues\n\nif_else(x &gt; 0, 'positive', 'negative', missing = 'missing') # Good: can explicitly handle NA\n\n[1] \"negative\" \"negative\" \"positive\" \"positive\" \"missing\" \n\nCodefun_dates &lt;- mdy('1-1-2025') + 0:365\n # ifelse(fun_dates &lt; today(), fun_dates + years(), fun_dates) # Bad: converts dates to integers\n # if_else(fun_dates &lt; today(), fun_dates + years(), fun_dates) # Good: keeps dates as dates\n\n\n\nCodedata(diamonds)\ndiamonds &lt;- diamonds |&gt; \n    slice_head(n = 1000)\n\n# Subset to diamonds that are less than 400 dollars or more than 10000 dollars.\ndiamonds |&gt; \n    filter(price &lt; 400 | price &gt; 10000)\n\n# A tibble: 30 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 20 more rows\n\nCode# Subset to diamonds that are between 500 and 600 dollars (inclusive).\ndiamonds |&gt; \n    filter(price &gt;= 500, price &lt;= 600)\n\n# A tibble: 90 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.35 Ideal     I     VS1      60.9  57     552  4.54  4.59  2.78\n 2  0.3  Premium   D     SI1      62.6  59     552  4.23  4.27  2.66\n 3  0.3  Ideal     D     SI1      62.5  57     552  4.29  4.32  2.69\n 4  0.3  Ideal     D     SI1      62.1  56     552  4.3   4.33  2.68\n 5  0.42 Premium   I     SI2      61.5  59     552  4.78  4.84  2.96\n 6  0.28 Ideal     G     VVS2     61.4  56     553  4.19  4.22  2.58\n 7  0.32 Ideal     I     VVS1     62    55.3   553  4.39  4.42  2.73\n 8  0.31 Very Good G     SI1      63.3  57     553  4.33  4.3   2.73\n 9  0.31 Premium   G     SI1      61.8  58     553  4.35  4.32  2.68\n10  0.24 Premium   E     VVS1     60.7  58     553  4.01  4.03  2.44\n# ℹ 80 more rows\n\nCode# How many diamonds are of either Fair, Premium, or Ideal cut (a total count)? What fraction of diamonds are of Fair, Premium, or Ideal cut?\n# First, do this a wrong way with ==. Predict the warning message that you will receive.\n# Second, do this the correct way with an appropriate logical operator.\n\n# Right way with %in%\ndiamonds |&gt; \n    mutate(is_fpi = cut %in% c(\"Fair\", \"Premium\", \"Ideal\")) |&gt; \n    summarize(num_fpi = sum(is_fpi), frac_fpi = mean(is_fpi))\n\n# A tibble: 1 × 2\n  num_fpi frac_fpi\n    &lt;int&gt;    &lt;dbl&gt;\n1     685    0.685\n\nCode# Are there any diamonds of Fair cut that are more than $3000? Are all diamonds of Ideal cut more than $2000?\ndiamonds |&gt; \n    filter(cut == \"Fair\") |&gt; \n    summarize(any_high = any(price &gt; 3000))\n\n# A tibble: 1 × 1\n  any_high\n  &lt;lgl&gt;   \n1 FALSE   \n\nCodediamonds |&gt; \n    filter(cut == \"Ideal\") |&gt; \n    summarize(all_high = all(price &gt; 2000))\n\n# A tibble: 1 × 1\n  all_high\n  &lt;lgl&gt;   \n1 FALSE   \n\nCode# Create two new categorized versions of price by looking up the documentation for if_else() and case_when():\n# price_cat1: “low” if price is less than 500 and “high” otherwise\n# price_cat2: “low” if price is less than 500, “medium” if price is between 500 and 1000 dollars inclusive, and “high” otherwise.\ndiamonds |&gt; \n    mutate(\n        price_cat1 = if_else(price &lt; 500, \"low\", \"high\"),\n        price_cat2 = case_when(\n            price &lt; 500 ~ \"low\",\n            price &gt;= 500 & price &lt;= 1000 ~ \"medium\",\n            price &gt; 1000 ~ \"high\"\n        )\n    )\n\n# A tibble: 1,000 × 12\n   carat cut       color clarity depth table price     x     y     z price_cat1\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43 low       \n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31 low       \n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31 low       \n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63 low       \n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75 low       \n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48 low       \n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47 low       \n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53 low       \n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49 low       \n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39 low       \n# ℹ 990 more rows\n# ℹ 1 more variable: price_cat2 &lt;chr&gt;\n\n\nNumerical data can be of class integer or numeric (representing real numbers).\n\nCodex &lt;- 1:3\nx\n\n[1] 1 2 3\n\nCodeclass(x)\n\n[1] \"integer\"\n\nCodex &lt;- c(1+1e-9, 2, 3)\nx\n\n[1] 1 2 3\n\nCodeclass(x)\n\n[1] \"numeric\"\n\n\n7 Adv Data Wrangling P2\n\nCodelibrary(stringr)\nstring1 &lt;- \"This is a string\"\nstring2 &lt;- 'If I want to include a \"quote\" inside a string, I use single quotes'\nstring3 &lt;- c(string1, string2) # string / character vector (of greater than length 1)\n\nstr_view(string1, html = TRUE)\n\n\n\n\n\nCreates a tab) (Creates a newline)\nCreating Strings\n\nCodedf_dates &lt;- tibble(\n    year = c(2000, 2001, 2002),\n    month = c(\"Jan\", \"Feb\", \"Mar\"),\n    day = c(3, 4, 5)\n)\n\ndf_dates |&gt;\n    mutate(\n        date1 = str_c(month, \"-\", day, \"-\", year),\n        date2 = str_glue(\"{month}-{day}-{year}\")\n    )\n\n# A tibble: 3 × 5\n   year month   day date1      date2     \n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;glue&gt;    \n1  2000 Jan       3 Jan-3-2000 Jan-3-2000\n2  2001 Feb       4 Feb-4-2001 Feb-4-2001\n3  2002 Mar       5 Mar-5-2002 Mar-5-2002\n\n\nExtracting Information with String\n\nCodedf &lt;- tibble(\n    word_id = 1:3,\n    word = c(\"replace\", \"match\", \"pattern\")\n)\n\ndf |&gt;\n    mutate(\n        word_length = str_length(word),\n        middle_pos = ceiling(word_length/2),\n        middle_letter = str_sub(word, middle_pos, middle_pos)\n    )\n\n# A tibble: 3 × 5\n  word_id word    word_length middle_pos middle_letter\n    &lt;int&gt; &lt;chr&gt;         &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;        \n1       1 replace           7          4 l            \n2       2 match             5          3 t            \n3       3 pattern           7          4 t            \n\n\nFinding patterns in strings with regular expressions\n\nCode# This regex finds \"a\" then \"b\" at most once (can't have 2 or more b's in a row)\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n\n[1] │ &lt;a&gt;\n[2] │ &lt;ab&gt;\n[3] │ &lt;ab&gt;b\n\nCode# There has to be an \"a\" followed by at least one b\n# This is why the first string \"a\" isn't matched\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n\n[2] │ &lt;ab&gt;\n[3] │ &lt;abb&gt;\n\nCode# There must be an \"a\" and then any number of b's (including zero)\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n\n[1] │ &lt;a&gt;\n[2] │ &lt;ab&gt;\n[3] │ &lt;abb&gt;\n\nCodestr_view(words, \"[aeiou][aeiou]m\")\n\n[154] │ cl&lt;aim&gt;\n[714] │ r&lt;oom&gt;\n[735] │ s&lt;eem&gt;\n[844] │ t&lt;eam&gt;\n\nCodestr_view(fruit, \"aa|ee|ii|oo|uu\")\n\n [9] │ bl&lt;oo&gt;d orange\n[33] │ g&lt;oo&gt;seberry\n[47] │ lych&lt;ee&gt;\n[66] │ purple mangost&lt;ee&gt;n\n\nCode# Words that start with y\nstr_view(words, \"^y\")\n\n[975] │ &lt;y&gt;ear\n[976] │ &lt;y&gt;es\n[977] │ &lt;y&gt;esterday\n[978] │ &lt;y&gt;et\n[979] │ &lt;y&gt;ou\n[980] │ &lt;y&gt;oung\n\nCode# Words that don't start with y\nstr_view(words, \"^[^y]\")\n\n [1] │ &lt;a&gt;\n [2] │ &lt;a&gt;ble\n [3] │ &lt;a&gt;bout\n [4] │ &lt;a&gt;bsolute\n [5] │ &lt;a&gt;ccept\n [6] │ &lt;a&gt;ccount\n [7] │ &lt;a&gt;chieve\n [8] │ &lt;a&gt;cross\n [9] │ &lt;a&gt;ct\n[10] │ &lt;a&gt;ctive\n[11] │ &lt;a&gt;ctual\n[12] │ &lt;a&gt;dd\n[13] │ &lt;a&gt;ddress\n[14] │ &lt;a&gt;dmit\n[15] │ &lt;a&gt;dvertise\n[16] │ &lt;a&gt;ffect\n[17] │ &lt;a&gt;fford\n[18] │ &lt;a&gt;fter\n[19] │ &lt;a&gt;fternoon\n[20] │ &lt;a&gt;gain\n... and 954 more",
    "crumbs": [
      "Exam 1",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>exam1</span>"
    ]
  },
  {
    "objectID": "src/exam/nyt_viz.html",
    "href": "src/exam/nyt_viz.html",
    "title": "Claire’s Exam 1",
    "section": "",
    "text": "About The Deep Dive\nI decided to follow Nick Paul’s Blog on the internet to learn how he approaches the process to creating a compelling data story. This blog recreates NYT’s COVID Tracker visualization which I looked at daily during the peak COVID epidemic. I highly enjoyed being able to understand the new labeling and data wrangling mechanisms that were introduced through this blog. It will certainly help me with activities in class that ask me to recreate this advanced visualizations.\nCodelibrary(dplyr)\nlibrary(readr)\nlibrary(ggplot2)\nCode# Reading from github dataset\nurl &lt;- \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\"\n\n# readr::read_csv\ndf_states &lt;- readr::read_csv(url)\n\n# glimpse dplyr function\nglimpse(df_states)\n\nRows: 61,942\nColumns: 5\n$ date   &lt;date&gt; 2020-01-21, 2020-01-22, 2020-01-23, 2020-01-24, 2020-01-24, 20…\n$ state  &lt;chr&gt; \"Washington\", \"Washington\", \"Washington\", \"Illinois\", \"Washingt…\n$ fips   &lt;chr&gt; \"53\", \"53\", \"53\", \"17\", \"53\", \"06\", \"17\", \"53\", \"04\", \"06\", \"17…\n$ cases  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, …\n$ deaths &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\nCodedf_ny_raw &lt;- df_states %&gt;% \n    filter(state == \"New York\") \n\nglimpse(df_ny_raw)\n\nRows: 1,118\nColumns: 5\n$ date   &lt;date&gt; 2020-03-01, 2020-03-02, 2020-03-03, 2020-03-04, 2020-03-05, 20…\n$ state  &lt;chr&gt; \"New York\", \"New York\", \"New York\", \"New York\", \"New York\", \"Ne…\n$ fips   &lt;chr&gt; \"36\", \"36\", \"36\", \"36\", \"36\", \"36\", \"36\", \"36\", \"36\", \"36\", \"36…\n$ cases  &lt;dbl&gt; 1, 1, 2, 11, 22, 44, 89, 106, 142, 173, 217, 326, 421, 610, 732…\n$ deaths &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 10, 18, 32, 39, 68…\nCodedf_ny_raw %&gt;% \n    ggplot(aes(x = date, y = cases)) +\n    geom_line()\n\n\n\n\n\n\nCode# The cases column has the cumulative cases up to that date.\n# Lag function takes the difference between the current date and the previous date.\n# = works in the same way as &lt;- \ndf_ny = df_ny_raw %&gt;% \n    mutate(cases = cases - lag(cases,\n                               default = 0))\n\ndf_ny %&gt;% \n    ggplot(aes(x = date, y = cases)) +\n    geom_line()\nCode# For day-to-day variability, sum the case counts from the current day and the previous 6 days and  \n# divide by 7 for days of week\n\ndf_ny_smooth = df_ny %&gt;% \n    mutate(smooth = sum(cases, \n                        lag(cases, 1), lag(cases, 2), \n                        lag(cases, 3), lag(cases, 4),\n                        lag(cases, 5), lag(cases, 6))\n                    /7)\n\n# Or, create a function to do so\nrolling_average &lt;- function(x, period = 7){\n    \n    total = x\n    \n    for(i in 1:period-1){\n        total = total + lag(x,i)\n    }\n    \n    return(total/period)\n    \n}\n\ndf_ny_smooth = df_ny %&gt;% \n    mutate(smooth = rolling_average(cases))\n\ndf_ny_smooth\n\n# A tibble: 1,118 × 6\n   date       state    fips  cases deaths smooth\n   &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 2020-03-01 New York 36        1      0   NA  \n 2 2020-03-02 New York 36        0      0   NA  \n 3 2020-03-03 New York 36        1      0   NA  \n 4 2020-03-04 New York 36        9      0   NA  \n 5 2020-03-05 New York 36       11      0   NA  \n 6 2020-03-06 New York 36       22      0   NA  \n 7 2020-03-07 New York 36       45      0   19.1\n 8 2020-03-08 New York 36       17      0   17.4\n 9 2020-03-09 New York 36       36      0   25.3\n10 2020-03-10 New York 36       31      0   28.9\n# ℹ 1,108 more rows\nCode# Basic Chart\nplot_nyt &lt;- df_ny_smooth %&gt;% \n    filter(!is.na(smooth)) %&gt;% \n    ggplot(aes(x = date, y = smooth)) +\n    geom_line(color = \"red\") + \n    geom_area(fill = \"red\", alpha = .25)\n\nplot_nyt\nCode# themes to note: panel.grid and background\nplot_nyt &lt;- plot_nyt +\ntheme(\n          panel.background = element_blank(),    \n          axis.text.y = element_text(angle = 0, vjust = -.5, \n                                     margin = margin(r = -30)),\n          panel.grid.minor = element_blank(),\n          panel.grid.major.x = element_blank(),\n          panel.grid.major.y = element_line(colour = 'light grey', \n                                          linetype = 'dashed',size = .35),\n          axis.ticks.x = element_line(color = \"light grey\"),\n          axis.ticks.y = element_blank(),\n          axis.line.x = element_line(colour = \"light grey\", linetype = \"solid\",\n                                     size = .5))\nplot_nyt\nCode# Adjusting the scales\nbreaks &lt;- scales::extended_breaks()(df_ny_smooth$smooth)\nbreaks &lt;- breaks[2:length(breaks)]\n\nplot_nyt &lt;- plot_nyt +\n    scale_x_date(expand = c(0,0),\n                 date_labels = \"%b-%Y\") +\n    scale_y_continuous(expand = c(0,0),\n                       breaks = breaks,\n                       limits = c(0,max(df_ny_smooth$smooth))) +\n    labs(y = NULL,\n         x = NULL,\n         title = \"New Reported Cases: New York\")\nplot_nyt\nCode# Creating label for the 7 day average; median of smooth dataframe\nmax_date = df_ny$date %&gt;% median() + 60\nmin_date = df_ny$date %&gt;% median() - 60\n\nlabel_vals = df_ny_smooth %&gt;% \n    filter(date &gt; min_date, date &lt; max_date) %&gt;% \n    arrange(desc(smooth)) %&gt;% \n    top_n(1)\n\nlabel_vals \n\n# A tibble: 1 × 6\n  date       state    fips  cases deaths smooth\n  &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 2021-09-19 New York 36     7724  54479  6547.\nCodeplot_nyt +\n    annotate(\"text\", x = label_vals$date, \n             y = label_vals$smooth * 1.4, \n             label = \"7-day\\naverage\",\n             size = 3.5,\n             fontface = \"plain\") +\n    annotate(\"segment\", x = label_vals$date, xend = label_vals$date,\n             y = label_vals$smooth, \n             yend = label_vals$smooth * 1.2,\n             size = .25)",
    "crumbs": [
      "Exam 1",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Claire's Exam 1</span>"
    ]
  },
  {
    "objectID": "src/exam/nyt_viz.html#things-i-learned",
    "href": "src/exam/nyt_viz.html#things-i-learned",
    "title": "Claire’s Exam 1",
    "section": "Things I learned",
    "text": "Things I learned\nI learned about dplyr function lag that takes a column that generates numbers cumulatively into one that subtracts previous values from the current one creating a day by day value.\nI also learned about how to create a loop in R studio to clean data. axis.text.y = element_text(angle = 0, vjust = -.5, margin = margin(r = -30)) would’ve been helpful to know when I was doing hw2. The axis. functions were new to me and showed me how I can change labeling in ggplot.\nextended_breaks() function from the scales package to automatically generate “nice” breaks (tick marks) for the y-axis based on the smooth column from the df_ny_smooth data frame.\nbreaks[2:length(breaks)] removes the first break value, typically 0. This is done to avoid a tick at 0 on the y-axis if it’s redundant or visually unhelpful.",
    "crumbs": [
      "Exam 1",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Claire's Exam 1</span>"
    ]
  },
  {
    "objectID": "src/exam/cp1.html",
    "href": "src/exam/cp1.html",
    "title": "cp1",
    "section": "",
    "text": "Adv Data Viz CP\n\nWhat geom do I use to create a barplot using the original raw data (not summarized)?\ngeom_bar\n\n\nWhat geom do I use to create a barplot using already summarized data (from count())?\ngeom_col\n\n\nWhich of these geom lines of code provides a proportional bar chart?\n\nggplot(aes(x, fill) + geom_bar(position = ‘fill’)\n\n\n\nAdv Spatial Viz P1 CP\n\nWhat are the two components of a CRS/GCS?\nDatum + Ellipsoid Model\n\n\nWhy is it insufficient to identify a location by its latitude and longitude?\nLongitude and latitude are calculated based on chosen a coordinate reference system (datum + ellipsoid model) and so that value of longitude and latitude of a location might change if the CRS changes.\n\n\nWhy do we need to be mindful about CRSs when working with different spatial datasets?\n\n\n\nDifferent CRSs may use different units (e.g., meters, feet). Consistency in units is essential for accurate distance and area calculations.\nJoining datasets from multiple sources requires a common CRS.\nDifferent datasets may use different CRSs. If these CRSs are not accounted for, the spatial points/regions will not align correctly on a map.\n\n\n\n\n\nAdv Data Wrangling P1 CP\n\nsqrt(2)^2 == 2 is [1] FALSE\nThe computer first calculates sqrt(2) and saves some but not all decimal places of 1.414214… so when you square that number, it is almost but not quite 2.\n\n\nTRUE & NA\n[1] NA\n\n\nTRUE | NA\n[1] TRUE\n\n\nsum(c(TRUE,TRUE,FALSE,TRUE))\n3\n\n\nif_else(condition,true,false)\nUseful when you are transforming values of a vector if a particular condition holds.\n\n\nparse_number()\nUseful when you have a variable that has non-numeric symbols such as $, %, or commas that you want to remove and convert to an integer or double numeric vector.\n\n\nRecycling in R refers to\nthe repeating of a short vector when arithmetic (and logical operations) is used on two vectors of different lengths.\n\n\nround(530.3,-2)\n(530.3 %/% 100) * 100\n\n\nfct_relevel()\nMoving a small number of levels to the beginning of the ordering or manually reordering levels.\n\n\nfct_recode()\nTransforming the values/levels of a factor variable to new labels\n\n\nfct_reorder()\nReordering the values/levels of a factor variable to by a different numeric/quantitative variable\n\n\nfct_infreq()\nReordering the values/levels of a factor variable to by the frequency of the levels\n\n\nWhat is ISO8601?\nInternational standard for writing date-time, largest unit of time to smallest unit, yyyy-mm-dd hh:mm.\n\n\nTo work with dates and times in R, we should:\nConvert character vectors such as “2024-07-23 1:35pm” to a date-time class (data type).\n\n\n\n\n\nAdv Data Wrangling P2 CP\n\nThe correct way to recreate paste0(“Letter of the Day:”,letters) with str_c() is\nstr_c(“Letter of the Day:”,letters, sep = ’’)\n\n\n“a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z”\nstr_c(letters, collapse = ‘,’)\nstr_flatten(letters,‘,’)\n\n\nTo separate a vector of strings (deliminted by commas) into columns of strings, use\nseparate_wider_delim()\n\n\nFor the following string,\n\nx1 &lt;- “textNi1o was particularly bad this year”\none of these functions will give you meaningful data and one will not. Why?\nread_csv(x1)$text\nread_csv(x1, locale = locale(encoding = “Latin1”))$text\nNon-English (non-ASCII) characters can be encoded in a wide variety of ways and read_csv() uses UTF-8 encoding by default.\n\n7. Which of these characters means that a pattern is optional (matches 0 or 1 time)?\n?\n\n8. Which of these characters means that a pattern is repeats (at least once)?\n+\n\n9. To replace all forward slahes with backslashes in “a/b/c/d/e”, use the following code:\nstr_replace_all(“a/b/c/d/e”,‘/’,“\\\\”)\n\n10. A primary key is\nis a variable or set of variables that uniquely identifies each observation\n\n11. A foreign key is\nis a variable (or set of variables) that corresponds to a primary key in another table\n\n12. A natural join is\na join that uses all variables that appear in both data frames as the join key\n\n13. Some examples of a non-equi join:\ncross join and inequality join",
    "crumbs": [
      "Exam 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>cp1</span>"
    ]
  },
  {
    "objectID": "src/appx/appx-sample1.html",
    "href": "src/appx/appx-sample1.html",
    "title": "Appendix A — Appendix Sample 1",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendix Sample 1</span>"
    ]
  },
  {
    "objectID": "src/appx/appx-sample2.html",
    "href": "src/appx/appx-sample2.html",
    "title": "Appendix B — Appendix Sample 2",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix Sample 2</span>"
    ]
  },
  {
    "objectID": "mm/mm.html",
    "href": "mm/mm.html",
    "title": "Appendix C — Mind Maps",
    "section": "",
    "text": "Creativity",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  },
  {
    "objectID": "mm/mm.html#creativity",
    "href": "mm/mm.html#creativity",
    "title": "Appendix C — Mind Maps",
    "section": "",
    "text": "0808-mind_map_example.jpg",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  },
  {
    "objectID": "mm/mm.html#review",
    "href": "mm/mm.html#review",
    "title": "Appendix C — Mind Maps",
    "section": "Review",
    "text": "Review\n\n\n\nreview-mm.png",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  },
  {
    "objectID": "mm/mm.html#advanced-data-visualization",
    "href": "mm/mm.html#advanced-data-visualization",
    "title": "Appendix C — Mind Maps",
    "section": "Advanced Data Visualization",
    "text": "Advanced Data Visualization\n\n\n\nadv-data-viz.jpg",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  }
]